\documentclass[12pt,a4paper]{article}

\usepackage{amsmath}
\usepackage{booktabs}

\usepackage{enumitem}
\setlist[enumerate]{noitemsep, topsep=0pt}
\setlist[itemize]{noitemsep, topsep=0pt}

\usepackage{fullpage}
\usepackage{multirow}
\usepackage{tabularx}

\setlength\parindent{0pt}

\begin{document}
\pagestyle{empty}

\textbf{CS 6320.002: Natural Language Processing} \\
\textbf{Spring 2020} \\

\textbf{Homework 1 Written Component -- 50 points} \\
\textbf{Issued 30 Aug. 2021} \\
\textbf{Due 11:59pm CDT 31 Sept. 2021} \\

\textbf{Deliverables:} Answers are to be typed directly into Gradescope.

\vspace{\baselineskip}

\textbf{What does it mean to ``show your work?"} Write out the math step-by-step; we should be able to clearly follow your reasoning from one step to another. (You can combine ``obvious" steps like simplifying fractions or doing basic arithmetic.) The point of showing your work is twofold: to get partial credit if your answer is incorrect, and to show us that you worked the problem yourself and understand it. We will deduct points if steps are missing.

\section{Math Review --- Multivariate Calculus}

The problems in this section refresh your memory on concepts from classes you have taken previously that we will use later in this course.

\subsection{Partial Derivatives (5 points)}

\begin{center}
$f(x, y, z) = \cfrac{xz}{y^2} + yz e^{x^2}$
\end{center}

What are $\cfrac{\partial f}{\partial x}$, $\cfrac{\partial f}{\partial y}$, and $\cfrac{\partial f}{\partial z}$? Show your work.

\subsection{The Chain Rule (5 points)}

\begin{align*}
f(x, y) &= xg(x,y) + 5y \\
g(x,y) &= x^2y - xh(x^2, y) \\
h(x, y) &= xy^2 + 2
\end{align*}

What are $\cfrac{\partial f}{\partial x}$ and $\cfrac{\partial f}{\partial y}$? Show your work.

\subsubsection{Extrema (5 points)}

\begin{center}
$f(x) = x \log_8 (x) + (1 - x) \log_8 (1 - x)$
\end{center}

What are the values of $x$ corresponding to the minima and maxima of $f(x)$ for $x \in [0, 1]$? Show your work (your math work; graphing it doesn't count!).

\section{Math Review --- Probability and Statistics}

The problems in this section refresh your memory on concepts from classes you have taken previously that we will use later in this course.

\subsection{Conditional Probability (5 points)}

Suppose there is a box containing 12 balls; six are orange, and six are green. You remove four balls at random, without replacing any. What is the probability that you remove four orange balls? Show your work.

\subsection{Bayes's Rule (5 points)}

Suppose you have two lab-mates. One (Friend A) talks about computer science 80\% of the time, and linguistics 20\% of the time; the other (Friend B) talks about linguistics 70\% of the time, and computer science 30\% of the time. One day, you find a typed note on your desk about computer science. Your lab-mates leave you notes equally often, so you don't know who left this one. What is the probability the note is from Friend A? Show your work.

\section{Language Modeling}

The problems in this section are based on the material covered in Week 2. \\

Suppose we have a training corpus consisting of two sentences:
\begin{itemize}
\item The cat sat in the hat on the mat
\item The dog sat on the log
\end{itemize}

\subsection{Smoothing --- Discounting and Katz Backoff (5 points)}

If we train a bigram Katz backoff model on this corpus, using $\beta = 0.75$ and no end token, what is $p_{katz}(\text{sat}|\text{dog})$? What is $p_{katz}(\text{sat}|\text{fish})$? Show your work.

\subsubsection{Smoothing --- Linear Interpolation (5 points)}

If we use linear interpolation between a bigram model and a unigram model, using $\lambda_1 = \lambda_2 = 0.5$ and no end token, what is $p_{inter}(\text{dog}|\text{the})$? What is $p_{inter}(\text{dog}|\text{log})$? Show your work.

\subsection{Perplexity (5 points)} 

What is the maximum possible value that the perplexity score can take? What is the minimum possible value it can take? Explain your reasoning and give an example of a training corpus and two test corpora, one that achieves the maximum possible perplexity score and one that achieves the minimum possible perplexity score. (You can do this with a single short sentence for each corpus.)

\subsection{Generation (5 points)}

Use your code from the programming component of this assignment to train three language models on the provided data file, {\tt shakespeare.txt}: one unigram model, one trigram, and one 5-gram. For each model, generate 5 random sentences with {\tt max\textunderscore length=10}. Show the sentences you generated with each model.

\vspace{\baselineskip}

What are some problems you see with the generated sentences? How do the sentences generated by the different models compare with each other? 

\subsection{Applications (5 points)}

Authorship identification is an important task in NLP. Can you think of a way to use language models to determine who wrote an unknown piece of text? Explain your idea and how it would work (you don't need to implement it). You must use language modeling the receive credit! Other approaches do not count.

\end{document}